# 1. Introduction to Transformers

Transformers are a type of deep learning model architecture that have become the foundation for many state-of-the-art models in natural language processing (NLP). Introduced in the paper "Attention is All You Need" by Vaswani et al. in 2017, transformers rely heavily on a mechanism called "self-attention".
